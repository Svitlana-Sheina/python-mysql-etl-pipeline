{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767c995-0953-4f72-8c78-52e39b80e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# PROJECT: Data Pipeline for an E-Commerce Company\n",
    "# CASE STUDY: Integrating Web-Scraped and API Data into SQL\n",
    "# ==========================================\n",
    "\n",
    "# The following notebook demonstrates a full data pipeline:\n",
    "# 1. Web scraping city-level data from Wikipedia\n",
    "# 2. Extracting geographical coordinates\n",
    "# 3. Storing and managing data in a MySQL database\n",
    "# 4. Enriching the dataset with population, weather, and flight information\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64148cf3-1d6a-4175-87ac-5161c14158d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1 — Web Scraping\n",
    "# ==========================================\n",
    "\n",
    "# Goal:\n",
    "# Extract structured city data (name, country, coordinates) from Wikipedia\n",
    "# and prepare it for insertion into the SQL database.\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e31f0-690b-4369-80fc-d97e02c2c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "!pip install lat-lon-parser\n",
    "from lat_lon_parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime(\"%d.%m.%Y\")\n",
    "print(today)\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lat_lon_parser import parse    \n",
    "\n",
    "\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\"]\n",
    "city_data = []\n",
    "countries = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for city in cities:\n",
    "    url = f\"https://www.wikipedia.org/wiki/{city}\"\n",
    "    headers = {'User-Agent': 'Chrome/134.0.0.0'}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    city_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    country = city_soup.find(class_=\"infobox-data\").get_text()\n",
    "    city_latitude = parse(city_soup.find(class_=\"latitude\").get_text())\n",
    "    city_longitude = parse(city_soup.find(class_=\"longitude\").get_text())\n",
    "    city_population = city_soup.find(string=\"Population\").find_next(\"td\").get_text()\n",
    "    city_population_clean = city_population.replace(\",\", \"\")\n",
    "    today = datetime.today().strftime(\"%d.%m.%Y\")\n",
    "    city_data.append({\"City\": city,\n",
    "                     \"Country\": country,\n",
    "                     \"Latitude\": city_latitude,\n",
    "                     \"Longitude\": city_longitude,\n",
    "                     \"Population\": int(city_population_clean),\n",
    "                     \"Population_Timestamp\": today})\n",
    "                 \n",
    "\n",
    "cities_df = pd.DataFrame(city_data)\n",
    "\n",
    "cities_main_df = cities_df[[\"City\",\"Country\",\"Latitude\",\"Longitude\" ]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1380323-ad1d-445f-82da-5aa8c5a8f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2 — SQL Setup\n",
    "# ==========================================\n",
    "\n",
    "# Create and configure the MySQL schema that will store\n",
    "# scraped and API-enriched data.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Preparing SQL\n",
    "# The following SQL commands (executed via Python) create the database\n",
    "# and the main tables used throughout the project.\n",
    "\n",
    "\n",
    "# Note:\n",
    "# The complete SQL schema (with all CREATE TABLE statements and foreign keys)\n",
    "# is also included in this repository as a separate file: `wiki_cities_full.sql`.\n",
    "# Refer to that file for the full SQL implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f4a9c-6069-478d-87b8-e77ccb651600",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- SQL:\n",
    "-- 1. Create a new database\n",
    "CREATE DATABASE wiki_cities;\n",
    "USE wiki_cities;\n",
    "\n",
    "-- 2. Create a master table for city information\n",
    "CREATE TABLE city_data (\n",
    "    city_id INT AUTO_INCREMENT,\n",
    "    city VARCHAR(50) NOT NULL,\n",
    "    country VARCHAR(50),\n",
    "    latitude DECIMAL(8,5),\n",
    "    longitude DECIMAL(8,5),\n",
    "    PRIMARY KEY (city_id) \n",
    "); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc211cf-571f-49d2-880d-a8525b391465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 3 — Sending Data to SQL\n",
    "# ==========================================\n",
    "\n",
    "# The scraped city data is now uploaded from the Jupyter Notebook\n",
    "# into the MySQL database using SQLAlchemy and pandas.\n",
    "\n",
    "# Purpose:\n",
    "# - To insert clean, structured city information into the `city_data` table\n",
    "# - To ensure that each city receives a unique city_id for later joins\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6da1e-2d51-46fb-8f3d-7790a30d25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "import my_sql_pass\n",
    "\n",
    "schema = \"wiki_cities\"\n",
    "host = \"127.0.0.1\"\n",
    "user = \"root\"\n",
    "password = my_sql_pass.my_password\n",
    "port = 3306\n",
    "\n",
    "connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "\n",
    "cities_main_df.to_sql('city_data',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f5c39-eba7-475f-8590-830885c0ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 4 — Pulling Data Back with City ID\n",
    "# ==========================================\n",
    "\n",
    "# After uploading the city data to SQL, retrieve it back into Python\n",
    "# to confirm successful insertion and to access the generated `city_id` values.\n",
    "# These IDs are essential for linking population, weather, and flight data\n",
    "# to their respective cities later in the pipeline.\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc63880-6ade-45b0-893b-f96c2b13d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data_sql = pd.read_sql(\"city_data\", con=connection_string)\n",
    "cities_df = cities_df.merge(city_data_sql[[\"city\", \"city_id\"]],left_on=\"City\", right_on=\"city\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ff1b1-35cb-48f3-91af-7b092bb30b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fc391-116e-4862-b406-197bb3cc2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = cities_df[['City', 'Population','Population_Timestamp','city_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302016f-35fd-42cd-b1da-f188e72e4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905a0a2-de3d-4c6f-925b-94c9ee644dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 5 — Population Data\n",
    "# ==========================================\n",
    "\n",
    "# This section creates the SQL table for storing population data\n",
    "# scraped from Wikipedia and links it to the corresponding city_id.\n",
    "#\n",
    "# The population values and timestamps are added later via Python\n",
    "# once the data is cleaned and formatted.\n",
    "# ----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6729ae-aa95-4141-9d5c-db40ec2454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- SQL:\n",
    "CREATE TABLE population (\n",
    "population_row_id INT auto_increment, \n",
    "city_id INT, \n",
    "City VARCHAR(50),\n",
    "Population VARCHAR(50), \n",
    "Population_Timestamp VARCHAR(50),\n",
    "PRIMARY KEY (population_row_id), \n",
    "FOREIGN KEY (city_id) REFERENCES city_data(city_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3af6b-2f3f-4872-8a22-a2eaa76664e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.to_sql('population',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8409a79-6a12-4556-9d3c-474844657455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 6 — Weather Data\n",
    "# ==========================================\n",
    "\n",
    "# Weather data is collected from the OpenWeather API and stored in SQL.\n",
    "# Each record includes forecast time, temperature, humidity, and other metrics.\n",
    "# The `city_id` column ensures correct linkage to the city_data table.\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e8739-603f-463d-821b-aeac9633498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import secret_api_key\n",
    "\n",
    "\n",
    "\n",
    "city_data_sql = pd.read_sql(\"city_data\", con=connection_string)\n",
    "cities = city_data_sql[\"city\"].tolist()\n",
    "API_key = secret_api_key.my_api_key\n",
    "weather_items = []  \n",
    "\n",
    "for city in cities:  \n",
    "    weather_data = requests.get(\n",
    "        f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={API_key}&units=metric\"\n",
    "    )\n",
    "    weather_data_json = weather_data.json()\n",
    "\n",
    "    for item in weather_data_json[\"list\"]:\n",
    "        weather_item = {\n",
    "            \"city\": str(city),\n",
    "            \"forecast_time\": datetime.strptime(item.get(\"dt_txt\"), \"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"temperature\": float(item[\"main\"].get(\"temp\", None)),\n",
    "            \"feels_like\": float(item[\"main\"].get(\"feels_like\", None)),\n",
    "            \"forecast\": str(item[\"weather\"][0].get(\"main\", None)),\n",
    "            \"humidity\": float(item[\"main\"].get(\"humidity\", None)),\n",
    "            \"clouds\": float(item[\"clouds\"].get(\"all\", None)),\n",
    "            \"wind_speed\": float(item[\"wind\"].get(\"speed\", None)),\n",
    "            \"rain_in_last_3h\": float(item.get(\"rain\", {}).get(\"3h\", 0)),\n",
    "        }\n",
    "        weather_items.append(weather_item)\n",
    "\n",
    "\n",
    "all_cities_df = pd.DataFrame(weather_items)\n",
    "all_cities_df = all_cities_df.merge(city_data_sql[['city', 'city_id']], on='city', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d20db-83d7-41ae-87d8-f6762cc15953",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df = all_flights_df[[\"dest_airport_icao\",\"number\",\"movement.airport.icao\",\"movement.airport.name\",\"movement.scheduledTime.utc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3a19b-9788-420e-a85e-78fe2d55177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df.loc[:, \"movement.scheduledTime.utc_dt\"] = pd.to_datetime(all_flights_df[\"movement.scheduledTime.utc\"], errors=\"coerce\")\n",
    "all_flights_df = all_flights_df.rename(columns={\n",
    "    \"movement.airport.icao\": \"movement_airport_icao\",\n",
    "    \"movement.airport.name\": \"movement_airport_name\",\n",
    "    \"movement.scheduledTime.utc_dt\": \"arrival_time\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18511e5-0f90-4ac7-878e-ebd799d592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df = all_flights_df[[\"dest_airport_icao\",\"number\",\"movement_airport_icao\",\"movement_airport_name\",\"arrival_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad644350-2ccd-4ecc-af3a-777bc06e1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df.to_sql('flights_data',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42c622-c5cd-4df3-86fe-19d141837766",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- SQL: \n",
    "CREATE TABLE weather_cities (\n",
    "weather_row_id INT auto_increment, \n",
    "city_id INT, \n",
    "city VARCHAR(50),\n",
    "forecast_time datetime,\n",
    "temperature decimal (5,2),\n",
    "feels_like decimal (5,2),\n",
    "forecast VARCHAR(50),\n",
    "humidity decimal (5,2),\n",
    "clouds decimal (5,2),\n",
    "wind_speed decimal (5,2),\n",
    "rain_in_last_3h decimal (5,2),\n",
    "PRIMARY KEY (weather_row_id), \n",
    "FOREIGN KEY (city_id) REFERENCES city_data(city_id)\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a40d3f-03ff-40c8-980c-e5c9b61698ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities_df.to_sql('weather_cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45417674-93ab-4506-aa99-fea1c86ad7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 7 — Airport Data\n",
    "# ==========================================\n",
    "\n",
    "# Airport data is retrieved from the Aerobox API and connected to the city table.\n",
    "# Each airport record includes ICAO and IATA codes, city name, and airport name.\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947b8d8-5c8b-4732-a9d1-a56ea6f6b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flights_api_key\n",
    "API_key_2 = flights_api_key.flights_api_k\n",
    "\n",
    "all_airports = []\n",
    "latitudes = city_data_sql[\"latitude\"]\n",
    "longitudes = city_data_sql[\"longitude\"]\n",
    "\n",
    "for lat, lon in zip(latitudes, longitudes):\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/airports/search/location/{lat}/{lon}/km/50/16\"\n",
    "    querystring = {\"withFlightInfoOnly\":\"true\"}\n",
    "    headers = {\n",
    "      \"X-RapidAPI-Key\": API_key_2,\n",
    "      \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"}\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      airports = pd.json_normalize(data.get('items', []))\n",
    "      all_airports.append(airports)\n",
    "\n",
    "all_airports_df = pd.concat(all_airports, ignore_index=True)\n",
    "\n",
    "\n",
    "all_airports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e1a6b-9176-4ac0-b21d-40340e85ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports_df = all_airports_df.merge(\n",
    "    city_data_sql[[\"city\", \"city_id\"]],\n",
    "    left_on=\"municipalityName\",\n",
    "    right_on=\"city\",\n",
    "    how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93044b10-ea42-4c58-8013-68e36b5bd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports_df = all_airports_df[[\"icao\", \"iata\", \"city\", \"city_id\", \"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04801f54-0836-44c8-a185-9b758096d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- SQL:\n",
    "CREATE TABLE airports_list (\n",
    "    airport_id INT AUTO_INCREMENT,\n",
    "    city_id INT,\n",
    "    city VARCHAR(50),\n",
    "    icao VARCHAR(50) UNIQUE, \n",
    "    iata VARCHAR(50),\n",
    "    name VARCHAR(100),\n",
    "    PRIMARY KEY (airport_id),\n",
    "    FOREIGN KEY (city_id) REFERENCES city_data(city_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1e40a-ef9a-4392-be7e-0d23a1266a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports_df.to_sql('airports_list',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407e0eb-f76d-43b9-a148-6e3b40ed2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 8 — Flight Movement Data\n",
    "# ==========================================\n",
    "\n",
    "# Flight movement data is also retrieved from the Aerobox API.\n",
    "# Each record links to the destination airport via ICAO code.\n",
    "# The table stores flight number, movement airport, and arrival time.\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74267f5a-3acb-41ab-a563-c26b408b0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights = []\n",
    "icaos = all_airports_df[\"icao\"]\n",
    "\n",
    "for icao in icaos:\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{icao}/2025-10-17T00:00/2025-10-17T11:59\"\n",
    "    querystring = {\"withLeg\":\"false\",\"direction\":\"Arrival\",\"withCancelled\":\"false\",\"withCodeshared\":\"false\",\"withCargo\":\"false\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": API_key_2,\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        flights = pd.json_normalize(data.get('arrivals', []))\n",
    "        flights[\"dest_airport_icao\"] = icao\n",
    "        all_flights.append(flights)\n",
    "    \n",
    "\n",
    "all_flights_df = pd.concat(all_flights, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02775798-387c-4975-bd1c-5aae4b63d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df = all_flights_df[[\"dest_airport_icao\",\"number\",\"movement.airport.icao\",\"movement.airport.name\",\"movement.scheduledTime.utc\"]]\n",
    "all_flights_df.loc[:, \"movement.scheduledTime.utc_dt\"] = pd.to_datetime(all_flights_df[\"movement.scheduledTime.utc\"], errors=\"coerce\")\n",
    "all_flights_df = all_flights_df.rename(columns={\n",
    "    \"movement.airport.icao\": \"movement_airport_icao\",\n",
    "    \"movement.airport.name\": \"movement_airport_name\",\n",
    "    \"movement.scheduledTime.utc_dt\": \"arrival_time\"\n",
    "})\n",
    "all_flights_df = all_flights_df[[\"dest_airport_icao\",\"number\",\"movement_airport_icao\",\"movement_airport_name\",\"arrival_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed486c-8275-4c03-b6cf-cc6dfb2fb52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- SQL:\n",
    "CREATE TABLE flights_data (\n",
    "    flight_id INT AUTO_INCREMENT,\n",
    "    dest_airport_icao VARCHAR(50),\n",
    "    `number` VARCHAR(50),\n",
    "    movement_airport_icao VARCHAR(50),\n",
    "    movement_airport_name VARCHAR(100),\n",
    "    arrival_time DATETIME,\n",
    "    PRIMARY KEY (flight_id),\n",
    "    FOREIGN KEY (dest_airport_icao) REFERENCES airports_list(icao)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3641e8-6e3f-4502-a5e5-485d41751646",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights_df.to_sql('flights_data',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22b1f3-dd4c-4c05-8de5-278e7dabec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 9 — Summary and Next Steps\n",
    "# ==========================================\n",
    "\n",
    "# This notebook demonstrates a complete ETL workflow:\n",
    "# - Web scraping city and population data from Wikipedia\n",
    "# - Collecting weather, airport, and flight data from external APIs\n",
    "# - Building and populating a relational MySQL database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
